# Triton Program
```python
import triton.language as tl

@triton.jit
def kernel():

def launch_kernel():
    kernel[grid]()
```

# Triton Data structure
## Scalar
```python
scalar = 42 
```

## Tensor Block
```python
# generated by "arange()" and ptr
# for example
offsets = tl.arange(0, BLOCK_SIZE)
ptr = x_ptr + offsets
```

## pointer
```python
# get from tensor.data_ptr()
x_ptr = x.data_ptr()
```

# Triton API
## triton.jit
用于使用 Triton 编译器 JIT 编译函数的装饰器
```python
@triton.jit
def kernel():
```
## load & store
```python
# ptr:      数据指针
# mask:     bool 掩码，决定哪些位置有效
# other:    掩码为 False 的默认值

tl.load(ptr, mask=None, other=None):
tl.store(ptr, value, mask=None):
```

## program_id
```python
# get block ID
pid_x = tl.program_id(axis=0)
pid_y = tl.program_id(axis=1)
```

## triton.cdiv
```python
grid = (triton.cdiv(M, block_M), triton.cdiv(N, block_N))
```

## mask
```python
mask = (expr)

# for example:
offsets = tl.arange(0, BLOCK_SIZE)
mask = offsets < n
```

## math
```python
# scalar
## ops
x = tl.sqrt(y)
x = tl.exp(y)
x = tl.log(y)

x = tl.cast(y, tl.float32)

# tensor block
## reduce
x = tl.sum(y)
x = tl.max(y)

z = tl.dot(x, y)
```

# Triton Autotune
```python
# Autotune 流程可以这样理解:
# 1. 编译时调用 generate_configs 生成所有可能的配置组合 configs
#     [
#        triton.Config({"BLOCK_SIZE_N": 32}, num_warps = 4),
#        triton.COnfig({"BLOCK_SIZE_N": 128}, num_warps = 8)
#     ]
# 运行时若遇到未缓存的 N，则遍历配置组合 configs 确定最优组合： best = meta["BLOCK_SIZE_N"]
# launch_kernel 方法使用 meta 对最优组合拆包，获得最优组合的 BLOCK_SIZE_N

def generate_configs():
    configs=[]
    do something
    return configs

@triton.autotune(configs=generate_configs, key=["N"])

@triton.jit
def kernel(x_ptr, N):
    do something

def launch_kernel(x):
    n = len(x)
    grid = lambda meta: (trition.cdiv(n, meta["BLOCK_SIZE_N"]))
    kernel[grid](
        x,
    )

```
